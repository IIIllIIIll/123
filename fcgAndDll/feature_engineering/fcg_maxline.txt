创建一个新的“工作函数”

这个新函数封装了原来 for 循环 内部的所有工作（处理一个文件）。这是并行化的关键。
# 这是一个新的函数，封装了处理单个文件的逻辑
def process_and_save_one_file(json_file_path: Path, fasttext_model_path: str, output_dir: str) -> bool:
    """
    加载、处理单个FCG JSON文件，并保存为.pt文件
    
    Args:
        json_file_path (Path): 输入的JSON文件路径
        fasttext_model_path (str): fasttext模型的文件路径
        output_dir (str): .pt文件的输出目录
        
    Returns:
        bool: 处理是否成功
    """
    
    # !!! 关键：每个进程必须独立加载模型
    # 因为模型对象不能在进程间安全传递
    try:
        fasttext_model = fasttext.load_model(fasttext_model_path)
    except Exception as e:
        logger.error(f"进程 {os.getpid()} 无法加载模型: {e}")
        return False

    logger.info(f"[PID {os.getpid()}] 开始处理文件: {json_file_path.name}")
    
    try:
        # 调用您已有的处理函数
        data = process_fcg_json(str(json_file_path), fasttext_model) #
        
        if data is not None:
            # 保存处理后的数据
            output_file = Path(output_dir) / f"{json_file_path.stem}_graph.pt"
            torch.save(data, output_file) #
            logger.info(f"[PID {os.getpid()}] 成功保存: {output_file}")
            return True
        else:
            logger.warning(f"[PID {os.getpid()}] 处理失败 (data is None): {json_file_path.name}")
            return False
            
    except Exception as e:
        logger.error(f"[PID {os.getpid()}] 处理 {json_file_path.name} 时出错: {e}", exc_info=True)
        return False
修改 batch_process_files 函数

现在，我们重写 batch_process_files，让它使用进程池来分发任务，而不是自己去 for 循环。
def batch_process_files(input_dir: str, output_dir: str, fasttext_model_path: str):
    """
    使用多进程批量处理所有FCG JSON文件
    """
    # 确保输出目录存在
    Path(output_dir).mkdir(parents=True, exist_ok=True)
    
    # 1. 收集所有任务
    input_path = Path(input_dir)
    json_files = list(input_path.glob("*_fcg.json")) #
    
    if not json_files:
        logger.warning(f"在 {input_dir} 中未找到 *_fcg.json 文件")
        return

    logger.info(f"找到 {len(json_files)} 个FCG JSON文件，开始多进程处理...")
    
    # 2. 设置工作进程数（例如，使用服务器的所有核心）
    num_workers = os.cpu_count()
    logger.info(f"启动 {num_workers} 个工作进程...")
    
    processed_count = 0
    failed_count = 0
    
    # 3. 使用 ProcessPoolExecutor
    with concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) as executor:
        
        # 提交所有任务到进程池
        # 我们将 fasttext_model_path 和 output_dir 作为固定参数传递
        futures = {
            executor.submit(process_and_save_one_file, json_file, fasttext_model_path, output_dir): json_file 
            for json_file in json_files
        }
        
        # 4. 收集结果
        for future in concurrent.futures.as_completed(futures):
            json_file = futures[future]
            try:
                success = future.result()
                if success:
                    processed_count += 1
                else:
                    failed_count += 1
            except Exception as e:
                logger.error(f"文件 {json_file.name} 在执行中抛出异常: {e}")
                failed_count += 1
    
    logger.info(f"批量处理完成: 成功 {processed_count} 个，失败 {failed_count} 个")


def main():
    """主函数"""
    # 配置路径 (和原来一样)
    input_dir = "/mnt/data1_l20_raid5disk/lbq_dataset/dataset/benign_ida_fcg"
    fasttext_model_path = "/mnt/data1_l20_raid5disk/lbq_dataset/output/fcg_fasttext/finetuned_fasttext_model.bin"
    output_dir = "/mnt/data1_l20_raid5disk/lbq_dataset/output/fcg_fasttext/processed_graphs" # 建议换个新目录

    logger.info("开始 FCG 特征提取...")
    
    # 调用修改后的批量处理函数
    batch_process_files(input_dir, output_dir, fasttext_model_path)
    
    logger.info("FCG 特征提取完成")

# (确保 main 在脚本末尾被调用)
if __name__ == "__main__":
    main()