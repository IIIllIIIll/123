import os
import torch
import torch.nn as nn
from torchvision import models, transforms
from torch.utils.data import Dataset, DataLoader
from PIL import Image
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from tqdm import tqdm
import random
import networkx as nx
import torch.nn.functional as F
import torch_geometric.nn as gnn
from torch_geometric.data import Data
from torch_geometric.utils import from_networkx

# -----------------------------
# 0. 固定随机种子
# -----------------------------
def set_seed(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    os.environ['PYTHONHASHSEED'] = str(seed)

# -----------------------------
# 1. 数据预处理
# -----------------------------
transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

# 自定义图像数据集类
class MalwareImageDataset(Dataset):
    def __init__(self, file_paths, labels, transform=None):
        self.file_paths = file_paths
        self.labels = labels
        self.transform = transform

    def __len__(self):
        return len(self.file_paths)

    def __getitem__(self, idx):
        image = Image.open(self.file_paths[idx]).convert("RGB")
        if self.transform:
            image = self.transform(image)
        label = torch.tensor(self.labels[idx], dtype=torch.long)
        return image, label

# 自定义图像+FCG数据集类
class MalwareMultiModalDataset(Dataset):
    def __init__(self, file_paths, labels, transform=None):
        self.file_paths = file_paths
        self.labels = labels
        self.transform = transform
        self.feature_dim = 18  # 严格设置特征维度为18

    def __len__(self):
        return len(self.file_paths)
    
    def __getitem__(self, idx):
        # 处理图像数据
        image_path = self.file_paths[idx]
        image = Image.open(image_path).convert("RGB")
        if self.transform:
            image = self.transform(image)
        
        # 处理FCG图数据
        apk_name = os.path.basename(os.path.dirname(image_path))
        fcg_path = image_path.replace("RGB_CLAHE.png", f"{apk_name}.apk_sfcg.graphml")
        
        # 如果FCG文件不存在，创建一个空图
        if os.path.exists(fcg_path):
            try:
                G = nx.read_graphml(fcg_path)
                # 为节点添加特征 - 使用level_vector作为特征
                for node in G.nodes():
                    # 检查节点是否有level_vector属性
                    if 'level_vector' in G.nodes[node]:
                        # 将level_vector转换为特征向量
                        level_vector = G.nodes[node]['level_vector']
                        # 确保level_vector是字符串并转换为列表
                        if isinstance(level_vector, str):
                            # 移除可能的括号和空格，然后分割
                            level_vector = level_vector.strip('[]() ').replace(' ', '')
                            features = [float(x) for x in level_vector.split(',') if x]
                        else:
                            features = level_vector
                        
                        # 严格检查特征维度
                        if len(features) != self.feature_dim:
                            if len(features) < self.feature_dim:
                                features.extend([0] * (self.feature_dim - len(features)))
                            else:
                                features = features[:self.feature_dim]
                            
                        G.nodes[node]['x'] = np.array(features, dtype=np.float32)
                    else:
                        # 如果没有level_vector，使用默认特征
                        G.nodes[node]['x'] = np.zeros(self.feature_dim, dtype=np.float32)
                
                # 转换为PyG数据
                graph_data = from_networkx(G)
                
                # 如果没有节点特征，添加默认特征
                if not hasattr(graph_data, 'x') or graph_data.x is None:
                    num_nodes = graph_data.num_nodes
                    graph_data.x = torch.zeros((num_nodes, self.feature_dim), dtype=torch.float)
                
                # 严格检查特征维度
                if graph_data.x.shape[1] != self.feature_dim:
                    raise ValueError(f"特征维度错误: 期望{self.feature_dim}，实际{graph_data.x.shape[1]}")
                
                # 确保edge_index存在
                if not hasattr(graph_data, 'edge_index') or graph_data.edge_index is None:
                    graph_data.edge_index = torch.zeros((2, 0), dtype=torch.long)
                
            except Exception as e:
                print(f"Error loading FCG for {fcg_path}: {e}")
                # 创建一个空图
                graph_data = Data(x=torch.zeros((1, self.feature_dim), dtype=torch.float), 
                                 edge_index=torch.zeros((2, 0), dtype=torch.long))
        else:
            # 创建一个空图
            graph_data = Data(x=torch.zeros((1, self.feature_dim), dtype=torch.float), 
                             edge_index=torch.zeros((2, 0), dtype=torch.long))
        
        label = torch.tensor(self.labels[idx], dtype=torch.long)
        return image, graph_data, label

# -----------------------------
# 2. 构建数据集
# -----------------------------
def collect_image_paths_and_labels(max_benign=None, malware_limits=None):
    """
    收集图像路径和标签
    
    参数:
    max_benign (int): 良性样本的最大数量，None表示不限制
    malware_limits (dict): 每种恶意软件类别的最大样本数量，格式为{'banking': 100, 'risk': 100, ...}
                          None表示不限制
    """
    good_root = "/mnt/data1_l20_raid5disk/CJX/good"
    malware_roots = {
        "banking": "/mnt/data1_l20_raid5disk/CJX/banking",
        "risk": "/mnt/data1_l20_raid5disk/CJX/risk",
        "SMS": "/mnt/data1_l20_raid5disk/CJX/SMS",
        "adware": "/mnt/data1_l20_raid5disk/CJX/adware",
    }

    img_paths, labels = [], []
    benign_count = 0
    malware_counts = {category: 0 for category in malware_roots.keys()}

    # 处理良性样本
    for subdir in os.listdir(good_root):
        # 如果达到最大良性样本数，则停止收集
        if max_benign is not None and benign_count >= max_benign:
            break
            
        # 检查是否是目录
        if not os.path.isdir(os.path.join(good_root, subdir)):
            continue
            
        # 修改路径格式以匹配实际结构
        base_name = subdir.replace(".apk_analysis", "")
        img_path = os.path.join(good_root, subdir, "RGB_CLAHE.png")
        fcg_path = os.path.join(good_root, subdir, f"{base_name}.apk_sfcg.graphml")
        
        # 只有当图像和FCG文件都存在时才添加样本
        if os.path.isfile(img_path) and os.path.isfile(fcg_path):
            img_paths.append(img_path)
            labels.append(0)
            benign_count += 1
        else:
            if not os.path.isfile(img_path):
                print(f"图像不存在: {img_path}")
            if not os.path.isfile(fcg_path):
                print(f"FCG不存在: {fcg_path}")

    # 处理恶意样本
    for category, malware_dir in malware_roots.items():
        # 检查是否需要限制该类别的样本数量
        category_limit = None
        if malware_limits is not None and category in malware_limits:
            category_limit = malware_limits[category]
        
        if not os.path.exists(malware_dir):
            print(f"目录不存在: {malware_dir}")
            continue
            
        for subdir in os.listdir(malware_dir):
            # 如果达到该类别的最大样本数，则停止收集
            if category_limit is not None and malware_counts[category] >= category_limit:
                break
                
            # 检查是否是目录
            if not os.path.isdir(os.path.join(malware_dir, subdir)):
                continue
                
            # 修改路径格式以匹配实际结构
            base_name = subdir.replace(".apk_analysis", "")
            img_path = os.path.join(malware_dir, subdir, "RGB_CLAHE.png")
            fcg_path = os.path.join(malware_dir, subdir, f"{base_name}.apk_sfcg.graphml")
            
            # 只有当图像和FCG文件都存在时才添加样本
            if os.path.isfile(img_path) and os.path.isfile(fcg_path):
                img_paths.append(img_path)
                labels.append(1)
                malware_counts[category] += 1
            else:
                if not os.path.isfile(img_path):
                    print(f"图像不存在: {img_path}")
                if not os.path.isfile(fcg_path):
                    print(f"FCG不存在: {fcg_path}")

    print(f"收集到的有效样本总数: {len(img_paths)}")
    print(f"良性样本数: {labels.count(0)}")
    print(f"恶意样本数: {labels.count(1)}")
    print("恶意样本类别分布:")
    for category, count in malware_counts.items():
        print(f"  - {category}: {count}")
    
    return img_paths, labels

# 自定义collate函数处理不同大小的图
def collate_fn(batch):
    images = torch.stack([item[0] for item in batch])
    graphs = [item[1] for item in batch]
    labels = torch.stack([item[2] for item in batch])
    return images, graphs, labels

# -----------------------------
# 3. 模型定义 + Fine-tuning
# -----------------------------
# 修改GCN层的输入维度
class GCNLayer(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(GCNLayer, self).__init__()
        self.conv = gnn.GCNConv(in_channels, out_channels)
        
    def forward(self, x, edge_index):
        return self.conv(x, edge_index)

class ExpertNetwork(nn.Module):
    def __init__(self, input_dim=256, hidden_dim=128, output_dim=64):
        super(ExpertNetwork, self).__init__()
        self.fc1 = nn.Linear(input_dim, hidden_dim)
        self.fc2 = nn.Linear(hidden_dim, output_dim)
        
    def forward(self, x):
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

class GatingNetwork(nn.Module):
    def __init__(self, input_dim=256, num_experts=4):
        super(GatingNetwork, self).__init__()
        self.gate = nn.Linear(input_dim, num_experts)
        
    def forward(self, x):
        return F.softmax(self.gate(x), dim=1)

class MixtureOfExperts(nn.Module):
    def __init__(self, input_dim=256, hidden_dim=128, output_dim=64, num_experts=4, k=2):
        super(MixtureOfExperts, self).__init__()
        self.num_experts = num_experts
        self.k = k  # 选择的专家数量
        
        # 创建多个专家网络
        self.experts = nn.ModuleList([
            ExpertNetwork(input_dim, hidden_dim, output_dim) 
            for _ in range(num_experts)
        ])
        
        # 门控网络
        self.gating = GatingNetwork(input_dim, num_experts)
        
    def forward(self, x):
        # 获取门控权重
        gates = self.gating(x)
        
        # 选择TopK专家
        _, indices = torch.topk(gates, self.k, dim=1)
        
        # 初始化输出
        final_output = torch.zeros(x.size(0), self.experts[0](x).size(1), device=x.device)
        
        # 对每个样本应用选定的专家
        for i in range(x.size(0)):  # 遍历批次中的每个样本
            sample_output = 0
            # 获取当前样本的TopK专家索引
            expert_indices = indices[i]
            # 获取当前样本的专家权重
            expert_weights = gates[i, expert_indices]
            # 归一化权重
            expert_weights = expert_weights / expert_weights.sum()
            
            # 应用每个选定的专家并加权
            for j, expert_idx in enumerate(expert_indices):
                expert_out = self.experts[expert_idx](x[i:i+1])
                sample_output += expert_out * expert_weights[j]
                
            final_output[i] = sample_output
            
        return final_output

class MultiModalMalwareModel(nn.Module):
    def __init__(self, num_experts=4, k=2):
        super(MultiModalMalwareModel, self).__init__()
        # 图像处理部分
        self.backbone = models.convnext_base(pretrained=True)
        self.backbone.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(1024, 128)  # 输出128维特征
        )
        
        # 图处理部分 - 修改输入维度为18
        self.gcn1 = GCNLayer(18, 64)
        self.gcn2 = GCNLayer(64, 128)
        
        # 共享的专家混合网络 - 输入维度为128，与两种特征维度匹配
        self.shared_moe = MixtureOfExperts(
            input_dim=128,  # 单个模态特征维度
            hidden_dim=64,
            output_dim=64,
            num_experts=num_experts,
            k=k
        )
        
        # 融合层
        self.fusion = nn.Linear(128, 64)  # 64+64=128
        
        # 分类器
        self.classifier = nn.Linear(64, 2)
        
    def forward(self, images, graphs):
        # 处理图像
        img_features = self.backbone(images)
        
        # 处理图 - 对每个图单独处理
        graph_features_list = []
        for graph in graphs:
            x, edge_index = graph.x, graph.edge_index
            
            # 应用GCN层
            x = F.relu(self.gcn1(x, edge_index))
            x = F.relu(self.gcn2(x, edge_index))
            
            # 全局池化得到图级别表示
            graph_feature = gnn.global_mean_pool(x, torch.zeros(x.size(0), dtype=torch.long, device=x.device))
            graph_features_list.append(graph_feature)
        
        # 将所有图特征堆叠成一个批次
        if graph_features_list:
            graph_features = torch.cat(graph_features_list, dim=0)
        img_features_processed = self.shared_moe(img_features)
        graph_features_processed = self.shared_moe(graph_features)
        
        # 融合处理后的特征
        combined = torch.cat([img_features_processed, graph_features_processed], dim=1)
        fused = F.relu(self.fusion(combined))
        
        # 分类
        output = self.classifier(fused)
        return output

# 将所有训练和测试代码移到 if __name__ == "__main__": 块中
if __name__ == "__main__":
    # 设置随机种子
    set_seed(42)
    
    # 收集数据，指定每种类别的最大样本数
    malware_limits = {
        "banking": 981,  # 银行木马限制为100个
        "risk": 987,     # 风险软件限制为150个
        "SMS": 1023 ,       # 短信木马限制为80个
        "adware": 956    # 广告软件限制为120个
    }
    all_paths, all_labels = collect_image_paths_and_labels(max_benign=3836, malware_limits=malware_limits)
    X_train, X_test, y_train, y_test = train_test_split(all_paths, all_labels, test_size=0.2, random_state=42)

    # 使用多模态数据集
    train_dataset = MalwareMultiModalDataset(X_train, y_train, transform=transform)
    test_dataset = MalwareMultiModalDataset(X_test, y_test, transform=transform)

    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=8, 
                             pin_memory=True, collate_fn=collate_fn)
    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=8, 
                            pin_memory=True, collate_fn=collate_fn)

    # 定义 device
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print("Using device:", device)

    # 创建模型时可以指定专家数量和TopK值
    model = MultiModalMalwareModel(num_experts=20, k=20).to(device)

    # 不冻结任何参数，实现全模型训练
    for param in model.parameters():
        param.requires_grad = True

    # -----------------------------
    # 4. 训练模型
    # -----------------------------
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
    
    # 创建日志记录
    log_file = open("/home/share/cjx/Train/log/training_metrics-expert20-k20.log", "w")
    log_file.write("Epoch,Train_ACC,Train_PRE,Train_R1,Train_F1,Test_ACC,Test_PRE,Test_R1,Test_F1\n")

    for epoch in range(100):
        model.train()
        total_loss = 0
        all_preds = []
        all_labels = []

        for images, graphs, labels in tqdm(train_loader, desc=f"Epoch {epoch+1}"):
            images = images.to(device)
            # 将图数据移到设备
            for i in range(len(graphs)):
                graphs[i] = graphs[i].to(device)
            labels = labels.to(device)
            
            optimizer.zero_grad()
            outputs = model(images, graphs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            total_loss += loss.item()
            _, preds = torch.max(outputs, 1)
            
            # 收集预测和标签用于计算指标
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

        # 计算训练指标
        train_acc = accuracy_score(all_labels, all_preds)
        train_pre = precision_score(all_labels, all_preds, average='macro')
        train_r1 = recall_score(all_labels, all_preds, average='macro')
        train_f1 = f1_score(all_labels, all_preds, average='macro')
        
        print(f"Epoch {epoch+1} Loss: {total_loss:.4f}")
        print(f"Train Metrics - ACC: {train_acc:.4f}, PRE: {train_pre:.4f}, R1: {train_r1:.4f}, F1: {train_f1:.4f}")

        # 测试阶段
        model.eval()
        all_preds = []
        all_labels = []

        with torch.no_grad():
            for images, graphs, labels in test_loader:
                images = images.to(device)
                # 将图数据移到设备
                for i in range(len(graphs)):
                    graphs[i] = graphs[i].to(device)
                labels = labels.to(device)
                
                outputs = model(images, graphs)
                _, preds = torch.max(outputs, 1)
                
                # 收集预测和标签用于计算指标
                all_preds.extend(preds.cpu().numpy())
                all_labels.extend(labels.cpu().numpy())

        # 计算测试指标
        test_acc = accuracy_score(all_labels, all_preds)
        test_pre = precision_score(all_labels, all_preds, average='macro')
        test_r1 = recall_score(all_labels, all_preds, average='macro')
        test_f1 = f1_score(all_labels, all_preds, average='macro')
        
        print(f"Test Metrics - ACC: {test_acc:.4f}, PRE: {test_pre:.4f}, R1: {test_r1:.4f}, F1: {test_f1:.4f}")
        
        # 记录日志
        log_file.write(f"{epoch+1},{train_acc:.4f},{train_pre:.4f},{train_r1:.4f},{train_f1:.4f},{test_acc:.4f},{test_pre:.4f},{test_r1:.4f},{test_f1:.4f}\n")
        log_file.flush()  # 确保立即写入文件

    # 关闭日志文件
    log_file.close()
    
    # 可选：保存模型
    torch.save(model.state_dict(), "/home/share/cjx/Train/log/multimodal_malware_model.pth")